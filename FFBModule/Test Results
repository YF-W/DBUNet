# Test Results
In general, the structure still follows the calculation idea of small convolution kernel, but uses more 1*1 convolution and residual to achieve feature fusion.
In order to verify the universality of the structure to lesions and models, extensive pluggable tests were carried out in the early stage of the project.

The test details are as follows


Through in-depth discussion, we believe that:
Other important open source models can be used to further test the effectiveness of our proposed modules.

The main methods are:
In the comparison method, select as many networks as possible, insert the modules we have constructed into them, and implement post-insertion testing in a completely consistent engineering environment to compare the network performance before and after the insertion.

The above experimental process not only achieves module verification, but also is an important part of our model tuning. We hope to apply this tuning method to as many other open-source models as possible to verify the tuning effect.


2) Specific solution to the problem
By analyzing the model of DBUNet and combining it with the profiling of all the comparative models, we have deployed the work as follows:

①	 The FFB Module will be transplanted for testing.
The FFB Module has the advantages of lightweight and pluggable, and at the same time is an important component of DBUNet proposed in this paper. Accordingly we plan to port the module for testing and analysis. On the other hand, in the discussion about AMDA, according to our observation, the Transformer structure in the comparison model does not adopt ViT architecture and AMDA has non-pluggable characteristics, so the AMDA module is not suitable for implementing comparisons.

②	 The test uses embedding rather than replacement.
In the early experiment of this modification, we used the REPLACEMENT method, but the effect was not satisfactory. We discussed that the original comparison network has a stable system with a close relationship before and after, and the modules are interconnected and strongly related. If imposed disassembly and replacement is used, it will have obvious damage to the original model, especially the absence of data processing module, which will greatly impair the analysis and image recovery ability of the network. Accordingly, we have switched to the addition of embedding to achieve the replacement of 10 models. It should be noted that in our comparison network, the DeepLab family accomplishes semantic segmentation through multiscale prediction, null convolution, and ASPP. However, these methods utilize cascaded structures, which make it difficult to embed portable modules.

These replaced models are: (a) U-Net; (b) SmaAt UNet; (c) Refine Net; (d) OAUNet; (e) Swin Transformer; (f) SUNet; (g) MTUNet; (h) FCN; (i) SegNet; (j) ResUNet
