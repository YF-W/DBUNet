# 探索Vision Transformer与CNN融合：针对ViT与CNN结合的注意力机制的影响下的模型效果对比结果

# Contrasting SOTA Models
![image](https://github.com/YF-W/DBUNet/assets/66008255/00eaaaaf-1ea8-4f88-8e4d-c38f229877b1)

In this study, 13 networks are selected for comparison. They include not only the classic traditional Semantic Segmentation structure (FCN, DeepLab v1-v3), but also the mainstream U-type codec and its derivatives (U-Net, ResUNet, SmaAt-UNet, OAU-net, SegNet, Refine Net), as well as the networks combined with Transformer (SUNet, Swin-Net, MTUNet). Although the proposed years of these networks are different, they are all the most cutting-edge SOTA at that time due to their excellent segmentation ability, so they also have good comparative value.

# Datasets
1) LUNG, this dataset is from https://www.kaggle.com/datasets/kmader/finding-lungs-in-ct-data.

2) SKIN-LESION, this dataset comes from https://www.kaggle.com/datasets/ojaswipandey/skin-lesion-dataset.

3) ISIC2017-Seborrheic Keratosis, this dataset comes from https://challenge.isic-archive.com/data/#2017.

4) ISIC-2017-Nevus. The dataset was acquired at https://challenge.isic-archive.com/data/#2017.

5) MICCAI-2020-Thyroid Nodule. The dataset is available at https://github.com/WAMAWAMA/TNSCUI2020-Seg-Rank1st. 

6) MICCAI-2015-CVC-ClinicDB. The dataset is available at: https://polyp.grand-challenge.org/CVCClinicDB/. 

# Indicators

![image](https://github.com/YF-W/DBUNet/assets/66008255/053a88b6-b13b-4a21-8eb3-9b7632e0a296)

# Results

![image](https://github.com/YF-W/DBUNet/assets/66008255/24819b70-3386-4fd5-8db3-6c9dad369e5c)

![image](https://github.com/YF-W/DBUNet/assets/66008255/201f01d3-4437-44e4-80e7-710d7dcdaa5b)

![image](https://github.com/YF-W/DBUNet/assets/66008255/3ac0734b-c85f-4486-8776-fb5a6173b57d)

![image](https://github.com/YF-W/DBUNet/assets/66008255/4042199a-bfe8-4573-8cc2-714c2b1e6b1d)

![image](https://github.com/YF-W/DBUNet/assets/66008255/4b6b668a-fb82-436b-946c-254cde1a4347)
